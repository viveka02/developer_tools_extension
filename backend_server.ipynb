{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viveka02/developer_tools_extension/blob/master/backend_server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Part 1: Importing the Tools ---\n",
        "# We're importing the necessary tools. FastAPI is our main framework.\n",
        "# Pydantic helps us make sure the data we receive is in the right format.\n",
        "# `os` and `httpx` are for talking to the external Claude AI.\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import httpx\n",
        "import os\n",
        "\n",
        "# --- Part 2: Setting up our FastAPI \"Kitchen\" ---\n",
        "# This line creates our main application. Think of it as opening the restaurant.\n",
        "app = FastAPI()\n",
        "\n",
        "# This is a secret key to talk to the Claude API.\n",
        "# In a real app, we would load this securely.\n",
        "# For this prototype, you can get one from Anthropic's website.\n",
        "# NOTE: The variable name `ANTHROPIC_API_KEY` is just an example.\n",
        "# We will use a secure way to manage this in the final product.\n",
        "API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\", \"YOUR_CLAUDE_API_KEY_HERE\")\n",
        "MODEL_NAME = \"claude-3-opus-20240229\"\n",
        "\n",
        "# --- Part 3: Defining our \"Order Slip\" ---\n",
        "# This class defines what an \"order\" from the frontend should look like.\n",
        "# It MUST contain a \"message\" which is a string (text).\n",
        "class UserMessage(BaseModel):\n",
        "    message: str\n",
        "\n",
        "# --- Part 4: The \"Waiter\" - Listening for Orders ---\n",
        "# This is the main \"endpoint\". It's a specific URL our frontend will send messages to.\n",
        "# When a POST request comes to \"/chat\", this function runs.\n",
        "@app.post(\"/chat\")\n",
        "async def handle_chat(user_message: UserMessage):\n",
        "    # This is where our magic happens. We take the user's message\n",
        "    # and send it to our \"specialist chef\" (the Claude AI).\n",
        "    ai_response = await call_claude_api(user_message.message)\n",
        "\n",
        "    # We send the AI's response back to the frontend.\n",
        "    return {\"reply\": ai_response}\n",
        "\n",
        "# --- Part 5: Talking to the \"Specialist Chef\" (Claude) ---\n",
        "# This is the most important function. It takes the user's message,\n",
        "# combines it with our secret instructions, and gets a response.\n",
        "async def call_claude_api(user_text: str):\n",
        "    # THIS IS THE HEART OF OUR INTELLECTUAL PROPERTY.\n",
        "    # We are pasting the entire \"AI Agent Design Document\" here.\n",
        "    # This turns a generic AI into OUR expert Empathos agent.\n",
        "    system_prompt = \"\"\"\n",
        "    You are an expert qualitative user researcher named 'Empathos'.\n",
        "    Your prime directive is to demonstrate empathy to understand the user's \"why.\"\n",
        "    ... (The rest of our entire Design Document goes in here) ...\n",
        "    \"\"\"\n",
        "\n",
        "    headers = {\n",
        "        \"x-api-key\": API_KEY,\n",
        "        \"anthropic-version\": \"2023-06-01\",\n",
        "        \"content-type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"max_tokens\": 1024,\n",
        "        \"system\": system_prompt, # Our secret sauce!\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": user_text}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # We use httpx to send the request over the internet.\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        response = await client.post(\n",
        "            \"https://api.anthropic.com/v1/messages\",\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            timeout=30.0 # Wait up to 30 seconds for a response\n",
        "        )\n",
        "\n",
        "    response_data = response.json()\n",
        "\n",
        "    # We extract just the text part of the AI's response to send back.\n",
        "    ai_text = response_data['content'][0]['text']\n",
        "    return ai_text"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "iyqiZJIcmrfM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}